{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Explore COCO Dataset**\n",
    "This notebook will be used for the basic exploration for COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import coco_dataset\n",
    "from coco_dataset import coco_dataset_download as cocod\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Globals\n",
    "home_dir = \"/home/tbaweja/\"\n",
    "dataset_path = os.path.join(home_dir, \"coco_dataset\")\n",
    "metadata_path = os.path.join(home_dir, \"wproj\", \"metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utils functions\n",
    "\n",
    "def unzip_file(src_file: str, dst_dir: str):\n",
    "    with zipfile.ZipFile(src_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dst_dir)\n",
    "\n",
    "def read_json(file_path: str):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_image_and_annotations(metadata_dict: dict, image_id: int):\n",
    "    data_path = os.path.join(dataset_path, \"train2014\")\n",
    "    image_to_ann = metadata_dict[\"imgToAnns\"][str(image_id)]\n",
    "    image_path = os.path.join(data_path, f\"COCO_train2014_000000{image_id}.jpg\")\n",
    "    annotations = [metadata_dict[\"anns\"][str(ann_idx)] for ann_idx in image_to_ann]\n",
    "    img = Image.open(image_path)\n",
    "    img_arr = np.array(img)\n",
    "    return img_arr, annotations\n",
    "\n",
    "def show_image_and_annotations(image: np.ndarray, annotations: list, plot_bbox: bool = True):\n",
    "    bboxes = [ann[\"bbox\"] for ann in annotations]\n",
    "    text_prefix = \"This image contains \"\n",
    "    for annotation in annotations:\n",
    "        text_annotation = annotation[\"utf8_string\"]\n",
    "        text_prefix += text_annotation + \", \"\n",
    "    # the length of images must be even\n",
    "    fig, ax = plt.subplots(figsize = (10, 6))\n",
    "    ax.imshow(image)\n",
    "\n",
    "    if plot_bbox:\n",
    "        for bbox in bboxes:\n",
    "            x, y, width, height = bbox\n",
    "            rect_instance = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect_instance)\n",
    "    \n",
    "    fig.suptitle(text_prefix, fontsize=10)\n",
    "    fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# zip_file_path = os.path.join(dataset_path, \"cocotext.v2.zip\")\n",
    "# dst_dir = dataset_path\n",
    "# unzip_file(zip_file_path, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_file_path = os.path.join(dataset_path, \"annotations_trainval2014.zip\")\n",
    "# dst_dir = dataset_path\n",
    "# unzip_file(zip_file_path, dst_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Link Annotations and Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_metadata = os.path.join(dataset_path, \"cocotext.v2.json\")\n",
    "# metadata_dict = read_json(raw_metadata)\n",
    "# metadata_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_metatdata = os.path.join(dataset_path, \"annotations\", \"captions_train2014.json\")\n",
    "captions_metadata_dict = read_json(captions_metatdata)\n",
    "captions_metadata_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_metatdata = os.path.join(dataset_path, \"annotations\", \"instances_train2014.json\")\n",
    "instances_metatdata_dict = read_json(instances_metatdata)\n",
    "instances_metatdata_dict[\"annotations\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process captions and instances metadata\n",
    "# caption_annotations = captions_metadata_dict[\"annotations\"]\n",
    "# caption_annotations = {item['image_id']: item for item in caption_annotations}\n",
    "\n",
    "# instance_annotations = instances_metatdata_dict[\"annotations\"]\n",
    "# instance_annotations = {item[\"image_id\"]: item for item in instance_annotations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_captions = sorted(captions_metadata_dict[\"annotations\"], key = lambda x: x[\"id\"])\n",
    "# sorted_captions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 167467\n",
    "image, annotations = load_image_and_annotations(metadata_dict, image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_and_annotations(image, annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create DataFrame for Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_caption = captions_metadata_dict[\"images\"]\n",
    "images_metadata_df = pd.DataFrame(images_caption)\n",
    "images_metadata_df = images_metadata_df.sort_values(\"id\")\n",
    "images_metadata_df = images_metadata_df.reset_index()\n",
    "images_metadata_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_captions = captions_metadata_dict[\"annotations\"]\n",
    "annotation_captions_df = pd.DataFrame(annotation_captions)\n",
    "annotation_captions_df = annotation_captions_df.sort_values(\"image_id\")\n",
    "annotation_captions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine image and captions\n",
    "\n",
    "# initialize the column \n",
    "images_metadata_df[\"image_captions\"] = None\n",
    "for idx, row in images_metadata_df.iterrows():\n",
    "    image_id = row[\"id\"]\n",
    "    caption_annotation_subset = annotation_captions_df.loc[annotation_captions_df[\"image_id\"] == image_id]\n",
    "    captions_list = []\n",
    "    for _, cap_row in caption_annotation_subset.iterrows():\n",
    "        captions_list.append(cap_row[\"caption\"])    \n",
    "    \n",
    "    images_metadata_df.at[idx, \"image_captions\"] = captions_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_categories = instances_metatdata_dict[\"categories\"]\n",
    "len(instance_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_annotations = instances_metatdata_dict[\"annotations\"]\n",
    "instance_annotations_df = pd.DataFrame(instance_annotations)\n",
    "instance_annotations_df = instance_annotations_df.sort_values(\"image_id\")\n",
    "instance_annotations_df = instance_annotations_df.reset_index()\n",
    "instance_annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate label information\n",
    "# initialize label column\n",
    "\n",
    "images_metadata_df[\"labels\"] = None\n",
    "for idx, row in images_metadata.iterrows():\n",
    "    image_id = row[\"id\"]\n",
    "    instance_subset_df = instance_annotations_df.loc[instance_annotations_df[\"image_id\"] == image_id]\n",
    "    labels_list = set()\n",
    "    for _, inst_row in instance_subset_df.iterrows():\n",
    "        cat_idx = inst_row[\"category_id\"]\n",
    "        labels_list.add(cat_idx)\n",
    "    \n",
    "    images_metadata_df.at[idx, \"labels\"] = labels_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store all metadata files\n",
    "file_path = os.path.join(metadata_path, \"image_caption_metdata.csv\")\n",
    "images_metadata_df.to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(metadata_path, \"instance_annotations.csv\")\n",
    "instance_annotations_df.to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
